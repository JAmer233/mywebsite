<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Neural Network Animation</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.4.0/p5.js"></script>
    <style>
        body {
            display: flex;
            flex-direction: column;
            align-items: center;
            height: 100vh;
            margin: 0;
            font-family: Arial, sans-serif;
        }
        #controls {
            margin: 10px;
        }
        #description {
            width: 800px;
            margin: 20px;
            text-align: justify;
        }
    </style>
</head>
<body>
    <div id="controls">
        <button id="startPauseBtn" onclick="toggleSimulation()">Start</button>
        <button onclick="resetSimulation()">Reset</button>
        <input type="range" id="speedSlider" min="1" max="10" value="5">
        <label for="speedSlider">Speed</label>
    </div>
    <div id="canvas-container"></div>
    <div id="description">
        <h2>Neural Network Visualization</h2>
        <p>This diagram represents a simple feedforward neural network with 5 input neurons, two hidden layers of 8 neurons each, and 4 output neurons. The animation demonstrates how information flows through the network:</p>
        <ul>
            <li><strong>Input Layer:</strong> The leftmost column of 5 neurons. Click on these to toggle their values between 0 and 1, simulating input data.</li>
            <li><strong>Hidden Layers:</strong> The two middle columns, each with 8 neurons. These process the input data.</li>
            <li><strong>Output Layer:</strong> The rightmost column of 4 neurons, representing the network's final output.</li>
            <li><strong>Connections:</strong> The gray lines between neurons represent the connections in the network.</li>
            <li><strong>Green Particles:</strong> These represent the flow of information through the network.</li>
        </ul>
        <p>The number in each neuron represents its current activation value. As you interact with the input neurons and the simulation runs, you'll see how changes propagate through the network, affecting the hidden and output layers.</p>

        <h1>Understanding Input Propagation in Neural Networks</h1>

    <h2>What Changing Inputs Does</h2>
    <p>When you change an input in the neural network visualization:</p>
    <ol>
        <li>You're simulating the introduction of different data to the network.</li>
        <li>This change initiates a cascade of updates through the entire network.</li>
        <li>The effects propagate from the input layer, through the hidden layers, to the output layer.</li>
    </ol>

    <h2>How It Updates Each Layer</h2>

    <h3>1. Input Layer</h3>
    <ul>
        <li>Changing an input neuron's value (toggling between 0 and 1) represents providing different input data.</li>
        <li>In real-world applications, inputs could be features of a dataset (e.g., pixel values in an image, or characteristics of a sample).</li>
    </ul>

    <h3>2. Hidden Layers</h3>
    <ul>
        <li>Each neuron in a hidden layer receives inputs from all neurons in the previous layer.</li>
        <li>For each hidden neuron:
            <ol>
                <li>It calculates a weighted sum of its inputs.</li>
                <li>This sum is passed through an activation function (in our case, the sigmoid function).</li>
                <li>The result becomes the neuron's output value.</li>
            </ol>
        </li>
    </ul>

    <h3>3. Output Layer</h3>
    <ul>
        <li>The process for the output layer is similar to the hidden layers.</li>
        <li>Each output neuron computes its value based on inputs from the last hidden layer.</li>
    </ul>

    <h2>Why It Updates</h2>
    <p>The network updates in response to input changes because:</p>
    <ol>
        <li>Neural networks are designed to transform input data into meaningful output.</li>
        <li>Each connection (synapse) has a weight that determines its importance.</li>
        <li>The network "learns" by adjusting these weights to produce the correct output for given inputs.</li>
    </ol>

    <h2>What It Represents</h2>
    <p>This process represents the fundamental operation of neural networks:</p>
    <ol>
        <li><strong>Information Processing</strong>: The network is processing information, transforming raw input data into a more abstract or task-specific representation.</li>
        <li><strong>Feature Extraction</strong>: Hidden layers often represent increasingly complex features or patterns found in the input data.</li>
        <li><strong>Decision Making</strong>: The output layer typically represents the network's decision or prediction based on the input.</li>
        <li><strong>Non-linearity</strong>: The activation functions (like sigmoid) introduce non-linearity, allowing the network to learn complex, non-linear relationships in data.</li>
        <li><strong>Distributed Representation</strong>: Information is stored across many neurons and connections, not in any single place.</li>
    </ol>

    <h2>Real-World Analogy</h2>
    <p>You can think of this process like a company:</p>
    <ul>
        <li>Input layer: Raw data or initial reports coming into the company.</li>
        <li>Hidden layers: Different departments processing and refining the information.</li>
        <li>Output layer: Executive decision based on the processed information.</li>
    </ul>
    <p>Changing an input is like changing a key piece of information in an initial report. This change affects how each department processes the data, ultimately influencing the final decision.</p>

    <h2>Importance in Machine Learning</h2>
    <p>This process is crucial because it allows neural networks to:</p>
    <ol>
        <li>Learn complex patterns in data.</li>
        <li>Make predictions or classifications based on new, unseen inputs.</li>
        <li>Generalize from training data to perform well on new, similar data.</li>
    </ol>
    <p>Understanding this process helps in designing, training, and interpreting neural networks for various machine learning tasks.</p>
    
    </div>
    <script>
        let neurons = [];
        let connections = [];
        let particles = [];
        let isRunning = false;
        let animationSpeed;

        function setup() {
            let canvas = createCanvas(800, 500);
            canvas.parent('canvas-container');
            setupNeurons();
            setupConnections();
            animationSpeed = document.getElementById('speedSlider');
        }

        function draw() {
            background(240);
            drawConnections();
            drawNeurons();
            drawLayerLabels();
            if (isRunning) {
                updateAnimation();
            }
            drawParticles();
        }

        function setupNeurons() {
            // Input layer
            for (let i = 0; i < 5; i++) {
                neurons.push({x: 100, y: 100 + i * 75, layer: 0, value: 0});
            }
            // Hidden layers
            for (let layer = 1; layer <= 2; layer++) {
                for (let i = 0; i < 8; i++) {
                    neurons.push({x: 300 + (layer - 1) * 200, y: 75 + i * 50, layer: layer, value: 0});
                }
            }
            // Output layer
            for (let i = 0; i < 4; i++) {
                neurons.push({x: 700, y: 150 + i * 75, layer: 3, value: 0});
            }
        }

        function setupConnections() {
            for (let i = 0; i < neurons.length; i++) {
                for (let j = 0; j < neurons.length; j++) {
                    if (neurons[i].layer < neurons[j].layer) {
                        connections.push({from: i, to: j, weight: random(-1, 1)});
                    }
                }
            }
        }

        function drawNeurons() {
            for (let neuron of neurons) {
                fill(255);
                stroke(0);
                ellipse(neuron.x, neuron.y, 30, 30);
                
                fill(0);
                textAlign(CENTER, CENTER);
                textSize(10);
                text(neuron.value.toFixed(2), neuron.x, neuron.y);
            }
        }

        function drawConnections() {
            for (let conn of connections) {
                let from = neurons[conn.from];
                let to = neurons[conn.to];
                stroke(200);
                line(from.x, from.y, to.x, to.y);
            }
        }

        function drawLayerLabels() {
            fill(0);
            textAlign(CENTER, BOTTOM);
            textSize(14);
            text("Input Layer", 100, 50);
            text("Hidden Layer 1", 300, 50);
            text("Hidden Layer 2", 500, 50);
            text("Output Layer", 700, 50);
        }

        function updateAnimation() {
            // Update neuron values
            for (let i = 0; i < neurons.length; i++) {
                if (neurons[i].layer === 0) continue; // Skip input layer
                let sum = 0;
                for (let conn of connections) {
                    if (conn.to === i) {
                        sum += neurons[conn.from].value * conn.weight;
                    }
                }
                neurons[i].value = sigmoid(sum);
            }

            // Create new particles
            for (let conn of connections) {
                if (random() < 0.1 * animationSpeed.value / 10) {
                    particles.push({
                        x: neurons[conn.from].x,
                        y: neurons[conn.from].y,
                        targetX: neurons[conn.to].x,
                        targetY: neurons[conn.to].y,
                        progress: 0
                    });
                }
            }
        }

        function drawParticles() {
            for (let i = particles.length - 1; i >= 0; i--) {
                let p = particles[i];
                p.progress += 0.02 * animationSpeed.value / 5;
                if (p.progress > 1) {
                    particles.splice(i, 1);
                } else {
                    let x = lerp(p.x, p.targetX, p.progress);
                    let y = lerp(p.y, p.targetY, p.progress);
                    fill(0, 255, 0);
                    noStroke();
                    ellipse(x, y, 5, 5);
                }
            }
        }

        function sigmoid(x) {
            return 1 / (1 + Math.exp(-x));
        }

        function resetSimulation() {
            for (let neuron of neurons) {
                neuron.value = 0;
            }
            particles = [];
        }

        function toggleSimulation() {
            isRunning = !isRunning;
            document.getElementById('startPauseBtn').textContent = isRunning ? 'Pause' : 'Start';
        }

        function mousePressed() {
            // Check if mouse is over an input neuron
            for (let i = 0; i < 5; i++) {
                let d = dist(mouseX, mouseY, neurons[i].x, neurons[i].y);
                if (d < 15) {
                    neurons[i].value = 1 - neurons[i].value; // Toggle between 0 and 1
                }
            }
        }
    </script>
</body>
</html>
